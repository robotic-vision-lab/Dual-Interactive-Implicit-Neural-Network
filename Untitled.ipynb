{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee5fdf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datamodules.sr_datamodule import *\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3ee4b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False, figsize=(16, 16))\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        print(img.min(), img.max())\n",
    "        img = F.to_pil_image(img)\n",
    "        print(np.asarray(img).min(), np.asarray(img).max())\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc347f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = SRDataModule(bin=True, reset_bin=False)\n",
    "dm.prepare_data()\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96d05a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DIV2K', 'train')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.hparams.trainsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1614300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DIV2K', 'train'),\n",
       " ('benchmark', 'B100'),\n",
       " ('benchmark', 'Set5'),\n",
       " ('benchmark', 'Set14'),\n",
       " ('benchmark', 'Urban100')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.hparams.testsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63211e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dm.train_dataloader()\n",
    "val_loader = dm.val_dataloader()\n",
    "test_loaders = dm.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7289f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n",
      "10\n",
      "[100, 100, 5, 14, 100]\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader.dataset))\n",
    "print(len(val_loader.dataset))\n",
    "print([len(test_loader.dataset) for test_loader in test_loaders])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbfe3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766186ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c8992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(make_grid(batch[3][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24456057",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(make_grid(batch[3][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377fdfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_loader in test_loaders:\n",
    "    batch = next(iter(test_loader))\n",
    "    show(make_grid(batch[4][0]))\n",
    "    show(make_grid(batch[4][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "150f3afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.components.liif import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "828a9c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LIIF().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "305fea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1,3,48,48).cuda()\n",
    "size = [64, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dedc359",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net(x, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ba8084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 64, 64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d0ab1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for split in range(5):\n",
    "        print((net(x,size,split) - net(x,size,0)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f1ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SRData(name='benchmark',split='Set14', bin=False, patch_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b875fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdde96f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.lr_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90fa2a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a4b232e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2097152"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_reserved()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a024c14",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m dm\u001b[38;5;241m.\u001b[39mdata_test:\n\u001b[1;32m----> 4\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[0;32m      5\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m scale \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m]:\n\u001b[0;32m      6\u001b[0m                 net(sample[scale][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m),sample[scale][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:])\n",
      "File \u001b[1;32m~\\.conda\\envs\\clat\\lib\\site-packages\\torch\\utils\\data\\dataset.py:471\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[1;32m--> 471\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\projects\\sisr\\src\\datamodules\\components\\srdata.py:83\u001b[0m, in \u001b[0;36mSRData.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     81\u001b[0m sample \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m scale \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscales:\n\u001b[1;32m---> 83\u001b[0m     lr, hr, filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     lr_patch, hr_patch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_patch(lr, hr, scale, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size)\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugment:\n",
      "File \u001b[1;32m~\\projects\\sisr\\src\\datamodules\\components\\srdata.py:106\u001b[0m, in \u001b[0;36mSRData._load_file\u001b[1;34m(self, idx, scale)\u001b[0m\n\u001b[0;32m    104\u001b[0m f_hr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames_hr_bin[idx]\n\u001b[0;32m    105\u001b[0m f_lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames_lr_bin[scale][idx]\n\u001b[1;32m--> 106\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(f_hr, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m _f:\n\u001b[0;32m    107\u001b[0m     hr \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(_f)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(f_lr, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m _f:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = LIIF().cuda()\n",
    "with torch.no_grad():\n",
    "    for dataset in dm.data_test:\n",
    "        for sample in dataset:\n",
    "            for scale in [2,3,4]:\n",
    "                net(sample[scale][0].unsqueeze(0),sample[scale][1].shape[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ab6bb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pixel_samples(inp, size, ranges=None, flatten=True):\n",
    "    \"\"\" Convert the image to coord-RGB pairs.\n",
    "        img: Tensor, (3, H, W)\n",
    "    \"\"\"\n",
    "    coord_seqs = []\n",
    "    for i, n in enumerate(size):\n",
    "        if ranges is None:\n",
    "            v0, v1 = -1, 1\n",
    "        else:\n",
    "            v0, v1 = ranges[i]\n",
    "        r = (v1 - v0) / (2 * n)\n",
    "        seq = v0 + r + (2 * r) * torch.arange(n, device=inp.device).float()\n",
    "        coord_seqs.append(seq)\n",
    "    hr_coord = torch.stack(torch.meshgrid(*coord_seqs, indexing='ij'), dim=-1)\n",
    "    if flatten:\n",
    "        hr_coord = hr_coord.view(-1, hr_coord.shape[-1])\n",
    "\n",
    "    cell = torch.ones_like(hr_coord)\n",
    "    cell[:, 0] *= 2 / size[-2]\n",
    "    cell[:, 1] *= 2 / size[-1]\n",
    "    print(hr_coord.shape, cell.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c01cb293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9216, 2]) torch.Size([9216, 2])\n"
     ]
    }
   ],
   "source": [
    "to_pixel_samples(torch.rand(16,3,48,48).cuda(), [96,96])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc44de4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
